# -*- coding: utf-8 -*-
"""ML Terapan Predictive Analytics

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1msPVuEhNPKi6FA92SOOsBF8Mb_i4On3v

**Proyek Pertama_Predictive Analytics**

Nama: Aisyah Amelia Zarah Juaita

Cohort ID: MC189D5X0464

Proyek Machine Learning: Klasifikasi Kualitas Wine

Sumber Data: kaggle

## 1. Import Library yang Dibutuhkan
"""

#Import Load data Library
from google.colab import files
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import zipfile

# Import train test split
from sklearn.model_selection import train_test_split

# Import Minmaxscaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import OneHotEncoder

#Import Model
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from lightgbm import LGBMClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.preprocessing import StandardScaler

"""## 2. Load Data"""

df = pd.read_csv('/content/wine_data.csv')
df.head()

"""Fungsi df = pd.read_csv digunakan untuk membaca file CSV dan mengubahnya menjadi sebuah DataFrame pandas, yaitu struktur data tabular seperti tabel yang memudahkan analisis data. '/content/wine_data.csv': Ini adalah path file CSV yang berisi data wine (anggur). Lalu fungsi df.head() untuk menampilkan 5 baris pertama dari DataFrame df untuk melihat sekilas isi data. Output menghasilkan Data ini berisi berbagai fitur kimia dan fisik dari sampel wine, seperti keasaman, kadar gula, kadar alkohol, dll. Setiap baris mewakili satu sampel wine. Kolom terakhir yaitu quality adalah nilai kualitas wine yang biasanya jadi target analisis.

## 3. Exploratory Data Analysis (EDA)

- Mendeskripsikan Variabel dari Dataset
"""

df

"""DataFrame diatas memiliki 21.000 baris dan 12 kolom, sebagai berikut:

1. `fixed_acidity` - Keasaman tetap: Asam yang tidak menguap saat proses fermentasi, seperti asam tartarat.

2. `volatile_acidity` - Keasaman yang mudah menguap, seperti asam asetat (bau cuka). Terlalu tinggi = wine rusak.

3. `citric_acid` - Asam sitrat: Menambah rasa segar/keasaman. Jumlah kecil bisa meningkatkan kualitas wine.

4. `residual_sugar` - Gula yang tersisa setelah fermentasi. Wine manis memiliki nilai lebih tinggi.

5. `chlorides` - Kandungan garam (biasanya natrium klorida). Terlalu tinggi = rasa asin/tidak enak.

6. `free_sulfur_dioxide` - SO₂ bebas: Digunakan untuk mencegah pertumbuhan mikroorganisme & oksidasi.

7. `total_sulfur_dioxide` - Total kandungan SO₂ (bebas + terikat). Terlalu banyak = berdampak negatif pada aroma dan rasa.

8. `density` - Kepadatan cairan wine. Dipengaruhi oleh kadar gula, alkohol, dan komposisi kimia lain.

9. `pH` - Tingkat keasaman (skala 0-14). pH rendah = asam tinggi.

10. `sulphates` - Tambahan sulfat untuk mengawetkan dan menstabilkan wine. Bisa juga memengaruhi rasa.

11. `alcohol` - Persentase kandungan alkohol dalam wine. Biasanya berkisar antara 8-14%.

12. `quality` - Skor kualitas wine, biasanya diberikan oleh panel uji rasa (skala 0-10). Target untuk model.

- Menampilkan Describe dari Dataset
"""

df.describe()

"""Fungsi df.describe() memberikan statistik deskriptif untuk setiap kolom numerik di DataFrame. Sangat berguna untuk memahami sebaran, nilai rata-rata, variasi, dan mendeteksi potensi outlier dalam dataset. Yang diantaranya:

1. `count` - Jumlah data non-null (semua = 21.000, berarti tidak ada missing value)

2. `mean` - Nilai rata-rata dari kolom.

3. `std` - Standar deviasi: ukuran penyebaran data terhadap rata-rata.

4. `min` - Nilai minimum.

5. `25%` - Kuartil pertama (Q1): 25% data berada di bawah nilai ini.

6. `50% (median)` - Kuartil kedua (Q2): nilai tengah (50% data di bawah dan 50% di atas).

7. `75%` - Kuartil ketiga (Q3): 75% data berada di bawah nilai ini.

8. `max` - Nilai maksimum.

- Menampilkan Informasi dari Dataset
"""

df.info()

"""Fungsi df.info() adalah Menampilkan struktur DataFrame, Melihat jumlah baris, kolom, dan tipe data masing-masing kolom, Mengetahui apakah ada missing values, Menampilkan penggunaan memori. Dari data di atas dapat disimpulkan bahwa:
1. Jumlah Datanya ada 21.000 dan memiliki 12 kolom.
2. Memiliki tipe data `float` ada 11 kolom, dan tipe data `int` ada 1 kolom (quality, skor kualitas).

- Menampilkan Jumlah dari Baris dan Kolom
"""

df.shape

"""Fungsi df.shape adalah properti dari DataFrame pandas yang menunjukkan dimensi data, yang dapat berupa jumlah baris dan juga jumlah kolom.

- Melihat apakah ada Data Duplikat atau tidak
"""

df.duplicated().sum()

"""Ternyata setelah dilakukan pengecekkan duplikat, terdapat (6060) yang duplikat.

- Membersihkan Data yang Duplikat
"""

df_cleaned = df.drop_duplicates()

df_cleaned.duplicated().sum()

"""Setelah dilakukan pembersihan, menghasilkan (0) yang dimana tidak terdapat data yang duplikasi.

- Melihat Missing Value
"""

df.isnull().sum()

"""Ternyata tidak terdapat missing value di dalam data tersebut.

- Melihat Proporsi pada kolom quality
"""

df.quality.value_counts(normalize=True)

"""Dapat disimpulkan bahwa dataset memiliki kelas quality yang seimbang, masing-masing skor kualitas (3-9) muncul sebanyak 14.29% dari total data (21.000).

## 4. Penanganan Outlier
"""

# Buat salinan data
df_clean = df.copy()

# Hilangkan kolom target dari kolom numerik yang akan dianalisis
numerical_cols = df_clean.drop(columns=['quality']).select_dtypes(include=['float64', 'int64']).columns

# Proses penghapusan outlier dengan metode IQR
for col in numerical_cols:
    Q1 = df_clean[col].quantile(0.25)
    Q3 = df_clean[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]

# Cek hasil
print(f"Jumlah data awal: {len(df)}")
print(f"Jumlah data setelah menghapus outlier: {len(df_clean)}")

"""Penanganan Outlier ini yaitu Melakukan pembersihan data dengan cara menghapus outlier (nilai pencilan) dari semua kolom numerik kecuali kolom quality menggunakan metode IQR (Interquartile Range). Yang dimana dari 21.000 baris data awal, sebanyak 111 baris dianggap outlier dan dihapus, dan data sekarang bersih dari nilai pencilan yang ekstrem berdasarkan IQR.


"""

df_clean.shape

"""Setelah dilakukannya outlier memiliki 20889 baris dan 12 kolom.

## 5. Univariate Analysis
"""

# Tentukan kolom kategorikal dan numerikal
categorical_cols = ['quality']
numerical_cols = [
    'fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar',
    'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide',
    'density', 'pH', 'sulphates', 'alcohol'
]

"""Berikut mengetahui kolom kategorikal dan numerikal."""

# Summary statistics numerikal
print("=== Summary Statistics (Numerikal) ===")
print(df[numerical_cols].describe().T)

"""Berikut adalah kode dan output statistik dari kolom numerikal, yang dimanan menghasilkan jumlah dari count, mean,std,min, 25%, 50%, 75%, dan max."""

# Visualisasi kolom numerikal: histogram & boxplot
for col in numerical_cols:
    fig, axes = plt.subplots(1, 2, figsize=(10, 4))

    # Histogram
    axes[0].hist(df[col], bins=30, edgecolor='k', color='skyblue')
    axes[0].set_title(f'Histogram of {col}')
    axes[0].set_xlabel(col)
    axes[0].set_ylabel('Frequency')

    # Boxplot
    axes[1].boxplot(df[col], vert=False)
    axes[1].set_title(f'Boxplot of {col}')
    axes[1].set_xlabel(col)

    plt.tight_layout()
    plt.show()

"""Kode dan output tersebut digunakan untuk visualisasi univariate  dari fitur numerik dalam DataFrame df, dengan menampilkan dua jenis grafik untuk setiap kolom numerik histogram dan boxplot. Histogram dan boxplot ini menghasilkan output yang Menunjukkan distribusi frekuensi data dan Menunjukkan persebaran data melalui nilai kuartil."""

# Summary statistics kategorikal
print("\n=== Summary Statistics (Kategorikal) ===")
for col in categorical_cols:
    print(f"\nDistribusi nilai untuk {col}:")
    print(df[col].value_counts())
    print(f"\nProporsi nilai untuk {col}:")
    print(df[col].value_counts(normalize=True))

"""Kode dan output diatas digunakan untuk menampilkan distribusi dan proporsi nilai pada kolom kategorikal `quality`. Hasilnya menunjukkan bahwa setiap nilai kualitas dari 3 hingga 9 muncul sebanyak 3.000 kali, sehingga distribusinya merata. Proporsi masing-masing kelas adalah 14,29%, yang menunjukkan bahwa data kategori ini seimbang dan tidak perlu penyesuaian khusus sebelum analisis atau pemodelan.

"""

# Visualisasi kolom kategorikal
for col in categorical_cols:
    plt.figure(figsize=(6, 4))
    sns.countplot(x=col, data=df, palette='Set2')
    plt.title(f'Countplot of {col}')
    plt.xlabel(col)
    plt.ylabel('Count')
    plt.show()

"""Pada kode digunakan untuk membuat visualisasi distribusi data pada kolom kategorikal menggunakan countplot dari library Seaborn. Dalam hal ini, kolom `quality` divisualisasikan untuk menunjukkan jumlah data pada setiap kategori nilai kualitas anggur. Karena data seimbang, grafik yang dihasilkan menunjukkan tinggi batang (bar) yang sama untuk setiap nilai `quality` dari 3 hingga 9. Visualisasi ini membantu dalam memahami seberapa banyak data yang dimiliki setiap kategori dan mengecek apakah terjadi ketidakseimbangan kelas.

## 6. Multivariate Analysis
"""

# Tentukan kolom
categorical_cols = ['quality']
numerical_cols = [
    'fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar',
    'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide',
    'density', 'pH', 'sulphates', 'alcohol'
]

"""Berikut menentukan mana kolom kategorikal dan numerikal."""

# Korelasi antar fitur numerik
plt.figure(figsize=(12, 10))
corr_matrix = df[numerical_cols].corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", square=True)
plt.title('Correlation Heatmap (Numerical Features)')
plt.show()

"""Berikut menampilkan korelasi antar fitur numerik dalam bentuk heatmap (peta korelasi). Korelasi ini dihitung menggunakan metode Pearson dan menunjukkan hubungan linier antara setiap pasangan fitur numerik dalam dataset. Hasilnya membantu kita melihat fitur mana yang saling berkorelasi kuat (positif atau negatif)."""

# Boxplot: Setiap fitur numerik terhadap quality
for col in numerical_cols:
    plt.figure(figsize=(8, 4))
    sns.boxplot(x='quality', y=col, data=df, palette='Set3')
    plt.title(f'{col} vs Wine Quality')
    plt.xlabel('Wine Quality')
    plt.ylabel(col)
    plt.show()

"""Berikut adalah untuk memvisualisasikan hubungan antara setiap fitur numerik dengan target variabel quality menggunakan boxplot. Boxplot ini menampilkan bagaimana distribusi nilai dari masing-masing fitur numerik berbeda di setiap level wine quality (dari 3 hingga 9). Visualisasi ini sangat berguna untuk mengidentifikasi fitur-fitur yang paling berpengaruh terhadap kualitas anggur dan dapat digunakan untuk analisis lanjutan seperti pemilihan fitur atau pemodelan prediktif."""

# Pairplot untuk beberapa fitur yang paling berpengaruh
selected_features = ['alcohol', 'sulphates', 'citric_acid', 'density', 'quality']
sns.pairplot(df[selected_features], hue='quality', palette='husl', diag_kind='kde')
plt.suptitle('Pairplot of Selected Features by Quality', y=1.02)
plt.show()

"""Berikut adalah pairplot menampilkan grafik scatterplot antara setiap pasangan fitur, sehingga kita bisa melihat hubungan dan pola antar fitur secara dua per dua. Di bagian diagonal, ditampilkan kurva kepadatan (KDE) yang memperlihatkan distribusi masing-masing fitur. Visualisasi ini membantu memahami korelasi antar fitur sekaligus bagaimana fitur-fitur tersebut berhubungan dengan kualitas anggur secara simultan.

## 7. Data Cleaning
"""

X = df_clean.drop("quality", axis=1)  # fitur (numerik)
y = df_clean["quality"]               # target (kategorikal)

"""Kode tersebut memisahkan data menjadi fitur dan target. Variabel `X` berisi semua kolom kecuali `quality`, yang digunakan sebagai fitur input, sedangkan `y` hanya berisi kolom `quality` sebagai target atau label yang ingin diprediksi. Dengan demikian, `X` adalah data numerik untuk analisis, dan `y` adalah nilai kualitas anggur yang menjadi fokus prediksi.

## 8. Train-Test-Split
"""

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

total_data = len(X)
print(f"Jumlah total dataset: {total_data}")
print(f"Jumlah data latih: {X_train.shape[0]}")
print(f"Jumlah data uji: {X_test.shape[0]}")

"""Kode dan output tersebut membagi dataset menjadi dua bagian: data latih (training) dan data uji (testing). Sebanyak 80% data (16.711 baris) digunakan untuk melatih model, dan 20% sisanya (4.178 baris) digunakan untuk menguji performa model. Pembagian ini dilakukan secara acak namun tetap menjaga proporsi kelas target (`quality`) sama pada kedua subset dengan menggunakan parameter `stratify=y`. Total data yang digunakan adalah 20.889 baris setelah pembersihan data.

"""

# Normalisasi (Standardisasi)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""Kode ini melakukan standarisasi data fitur pada dataset latih dan uji menggunakan `StandardScaler`. Dengan standarisasi, setiap fitur diubah sehingga memiliki rata-rata nol dan standar deviasi satu. Ini penting supaya model machine learning tidak bias terhadap fitur dengan skala besar dan bisa belajar dengan lebih baik serta stabil. Proses `fit_transform` diterapkan pada data latih untuk menghitung parameter standarisasi, kemudian `transform` diterapkan ke data uji agar menggunakan skala yang sama.

"""

# Final Output
print("\n=== Data Shapes ===")
print(f"X_train: {X_train_scaled.shape}")
print(f"X_test: {X_test_scaled.shape}")
print(f"y_train: {y_train.shape}")
print(f"y_test: {y_test.shape}")

"""Kode dan output ini menampilkan ukuran (shape) dari data setelah split dan standarisasi. `X_train` dan `X_test` masing-masing memiliki 11 fitur dan jumlah baris sesuai data latih dan uji. Sedangkan `y_train` dan `y_test` berisi label target dengan jumlah yang sama seperti data fitur latih dan uji. Ini memastikan data sudah siap untuk proses pelatihan model.

## 9. Model Development
"""

!pip install lazypredict

from lazypredict.Supervised import LazyClassifier

klasifikasi_otomatis = LazyClassifier(verbose=0, ignore_warnings=True)
hasil_model, hasil_prediksi = klasifikasi_otomatis.fit(X_train, X_test, y_train, y_test)
print(hasil_model.sort_values("Accuracy", ascending=False))

"""Kesimpulannya adalah menghasilkan evaluasi yaitu:

1. Model RandomForestClassifier adalah model yang memiliki akurasi paling tinggi dibandingkan model yang lain yaitu 0.62.
2. Model DecisionTreeClassifier juga menghasilkan akurasi yang tinggi yaitu 0.60.   
3. Model Perceptron memiliki urutan akurasi 2 terendah yaitu menghasilkan 0.24.
4. Model DummyClassifier adalah model yang paling kecil akurasi nya yaitu 0.14.

Selain model beberapa model yang disebutkan masih banyak lagi model-model yang lainnya. Dan juga selain akurasi, terdapat Balanced Accuracy, ROC, AUC, F1, Score dan Time Taken.

"""

plt.figure(figsize=(12, 8))
sorted_results = hasil_model.sort_values(by='Accuracy', ascending=True)

# Buat barplot dengan palet warna yang berbeda
sns.barplot(
    x=sorted_results['Accuracy'],
    y=sorted_results.index,
    palette='coolwarm'
)

plt.title('Perbandingan Akurasi Model (LazyClassifier)', fontsize=14)
plt.xlabel('Akurasi')
plt.ylabel('Model')
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""Dapat dilihat dari Perbandingan Akurasi Model (LazyClassifier) ini didapatkan model yang memiliki akurasi tinggi yaitu RandomForestClassifier dan model yang memiliki akurasi paling rendah yaitu DummyClassifier."""

models = pd.DataFrame(index=['accuracy_score'],
                      columns=['RandomForestClassifier', 'ExtraTreesClassifier', 'DecisionTreeClassifier', 'BaggingClassifier', 'LGBMCClassifier'])

"""Disini memilih 5 model yaitu:

1. RandomForestClassifier
2. ExtraTreesClassifier
3. DecisionTreeClassifier
4. BaggingClassifier
5. LGBMCClassifier

## 10. Modeling

- RandomForestClassifier
"""

model_rf = RandomForestClassifier(n_estimators=100, random_state=42)
model_rf.fit(X_train_scaled, y_train)

"""Pada tahap ini digunakan untuk membuat dan melatih model Random Forest Classifier pada data pelatihan. Pertama, dibuat objek model Random Forest dengan 100 pohon keputusan (n\_estimators=100) dan pengaturan random\_state=42 agar hasil pelatihan dapat direproduksi secara konsisten. Selanjutnya, model tersebut dilatih menggunakan data fitur yang sudah diskalakan (`X_train_scaled`) beserta label targetnya (`y_train`). Proses pelatihan ini memungkinkan model untuk mempelajari pola dari data sehingga nantinya dapat digunakan untuk melakukan prediksi pada data baru.

"""

# Menggunakan model RandomForestClassifier untuk memprediksi data uji
rf_pred = model_rf.predict(X_test_scaled)
# Menyimpan skor akurasi ke dalam dictionary 'models'
models['RandomForestClassifier_accuracy'] = accuracy_score(y_test, rf_pred)

"""Kode tersebut digunakan untuk melakukan prediksi dan evaluasi model Random Forest yang sudah dilatih sebelumnya. Pertama, model RandomForestClassifier digunakan untuk memprediksi label pada data uji yang sudah diskalakan (`X_test_scaled`) dengan memanggil metode `predict`, kemudian hasil prediksi disimpan dalam variabel `rf_pred`. Selanjutnya, akurasi prediksi tersebut dihitung dengan membandingkan hasil prediksi `rf_pred` dengan label sebenarnya `y_test` menggunakan fungsi `accuracy_score`. Nilai akurasi yang didapat kemudian disimpan dalam sebuah dictionary bernama `models` dengan kunci `'RandomForestClassifier_accuracy'`, sehingga hasil evaluasi performa model ini dapat dengan mudah diakses dan dibandingkan dengan model lain.

- ExtraTreesClassifier
"""

model_et = ExtraTreesClassifier(n_estimators=100, random_state=42)
model_et.fit(X_train_scaled, y_train)

"""Pada tahap ini digunakan untuk membuat dan melatih model Extra Trees Classifier pada data pelatihan. Pertama, objek model Extra Trees dibuat dengan menggunakan 100 pohon keputusan (`n_estimators=100`) dan pengaturan `random_state=42` agar hasil pelatihan dapat direproduksi secara konsisten. Setelah itu, model tersebut dilatih dengan menggunakan data fitur yang telah diskalakan (`X_train_scaled`) beserta label targetnya (`y_train`). Proses pelatihan ini memungkinkan model Extra Trees untuk mempelajari pola dari data pelatihan sehingga nantinya dapat digunakan untuk melakukan prediksi pada data baru.

"""

# Menggunakan model ExtraTreesClassifier untuk memprediksi data uji
et_pred = model_et.predict(X_test_scaled)
# Menyimpan skor akurasi ke dalam dictionary 'models'
models['ExtraTreesClassifier_accuracy'] = accuracy_score(y_test, et_pred)

"""Kode ini digunakan untuk melakukan prediksi dan evaluasi model Extra Trees Classifier yang telah dilatih sebelumnya. Pertama, model Extra Trees digunakan untuk memprediksi label pada data uji yang sudah diskalakan (`X_test_scaled`) dengan memanggil metode `predict`, dan hasil prediksi tersebut disimpan dalam variabel `et_pred`. Selanjutnya, akurasi dari prediksi ini dihitung dengan membandingkan hasil prediksi `et_pred` dengan label sebenarnya `y_test` menggunakan fungsi `accuracy_score`. Nilai akurasi yang diperoleh kemudian disimpan dalam sebuah dictionary bernama `models` dengan kunci `'ExtraTreesClassifier_accuracy'`, sehingga memudahkan pengelolaan dan perbandingan performa model dengan model-model lain.

- DecisionTreeClassifier
"""

model_dt = DecisionTreeClassifier(criterion='gini', max_depth=None, random_state=42)
model_dt.fit(X_train_scaled, y_train)

"""Pada tahap ini digunakan untuk membuat dan melatih model Decision Tree Classifier pada data pelatihan. Model Decision Tree dibuat dengan menggunakan kriteria pemisahan berdasarkan indeks Gini (`criterion='gini'`), tanpa batasan kedalaman pohon (`max_depth=None`), dan dengan pengaturan `random_state=42` agar hasil pelatihan dapat direproduksi secara konsisten. Setelah itu, model tersebut dilatih menggunakan data fitur yang sudah diskalakan (`X_train_scaled`) beserta label targetnya (`y_train`). Proses pelatihan ini memungkinkan model Decision Tree untuk mempelajari pola dari data pelatihan sehingga dapat digunakan untuk melakukan prediksi pada data uji atau data baru nantinya.

"""

# Menggunakan model Decision Tree untuk memprediksi data uji
dt_pred = model_dt.predict(X_test_scaled)
# Menyimpan skor akurasi ke dalam dictionary 'models'
models['DecisionTreeClassifier_accuracy'] = accuracy_score(y_test, dt_pred)

"""Kode ini digunakan untuk melakukan prediksi dan evaluasi model Decision Tree yang telah dilatih sebelumnya. Pertama, model Decision Tree digunakan untuk memprediksi label pada data uji yang sudah diskalakan (`X_test_scaled`) dengan memanggil metode `predict`, dan hasil prediksi disimpan dalam variabel `dt_pred`. Kemudian, akurasi prediksi dihitung dengan membandingkan hasil prediksi `dt_pred` dengan label sebenarnya `y_test` menggunakan fungsi `accuracy_score`. Nilai akurasi yang diperoleh disimpan dalam dictionary bernama `models` dengan kunci `'DecisionTreeClassifier_accuracy'`, sehingga hasil evaluasi performa model ini dapat dengan mudah disimpan dan dibandingkan dengan model lain.

- BaggingClassifier
"""

# BaggingClassifier
model_bagging = BaggingClassifier(
    estimator=DecisionTreeClassifier(),
    n_estimators=50,
    random_state=42
)
model_bagging.fit(X_train_scaled, y_train)

"""Pada tahap ini digunakan untuk membuat dan melatih model BaggingClassifier yang menggunakan Decision Tree sebagai estimator dasar. Model Bagging dibuat dengan menggabungkan 50 pohon keputusan (`n_estimators=50`) untuk membentuk ensemble yang lebih kuat dan stabil, serta menggunakan `random_state=42` agar hasil pelatihan dapat direproduksi. Estimator dasar yang digunakan adalah `DecisionTreeClassifier` standar tanpa parameter khusus. Setelah itu, model Bagging dilatih menggunakan data fitur yang sudah diskalakan (`X_train_scaled`) dan label targetnya (`y_train`). Dengan cara ini, model belajar pola dari data pelatihan dan diharapkan mampu mengurangi overfitting yang biasanya terjadi pada pohon keputusan tunggal, sehingga menghasilkan prediksi yang lebih akurat dan andal.

"""

# Menggunakan model BaggingClassifier untuk memprediksi data uji
bagging_pred = model_bagging.predict(X_test_scaled)
# Menyimpan skor akurasi ke dalam dictionary 'models'
models['BaggingClassifier_accuracy'] = accuracy_score(y_test, bagging_pred)

"""Kode ini digunakan untuk melakukan prediksi dan evaluasi model BaggingClassifier yang telah dilatih sebelumnya. Model Bagging digunakan untuk memprediksi label pada data uji yang sudah diskalakan (`X_test_scaled`) dengan memanggil metode `predict`, dan hasil prediksi disimpan dalam variabel `bagging_pred`. Selanjutnya, akurasi prediksi dihitung dengan membandingkan hasil prediksi `bagging_pred` dengan label sebenarnya `y_test` menggunakan fungsi `accuracy_score`. Nilai akurasi yang diperoleh kemudian disimpan dalam dictionary bernama `models` dengan kunci `'BaggingClassifier_accuracy'`, sehingga memudahkan penyimpanan dan perbandingan performa model ini dengan model-model lain yang diuji.

- LGBMCClassifier
"""

# Inisialisasi model LightGBM dengan parameter yang diberikan
model_lgb = LGBMClassifier(
    boosting_type='gbdt',
    num_leaves=31,
    learning_rate=0.1,
    n_estimators=100,
    random_state=42
)
model_lgb.fit(X_train_scaled, y_train)

"""Pada tahap ini digunakan untuk menginisialisasi dan melatih model LightGBM (Light Gradient Boosting Machine) dengan parameter tertentu. Model dibuat menggunakan metode boosting tipe `gbdt` (Gradient Boosting Decision Tree) dengan jumlah daun pohon maksimum sebanyak 31 (`num_leaves=31`), laju pembelajaran sebesar 0.1 (`learning_rate=0.1`), dan jumlah estimators atau pohon sebanyak 100 (`n_estimators=100`). Pengaturan `random_state=42` digunakan agar hasil pelatihan dapat direproduksi secara konsisten. Setelah model diinisialisasi, proses pelatihan dilakukan dengan menggunakan data fitur yang sudah diskalakan (`X_train_scaled`) dan label targetnya (`y_train`), sehingga model dapat mempelajari pola dari data pelatihan untuk digunakan dalam prediksi data baru.

"""

# Menggunakan model LightGBM untuk memprediksi data uji
lgb_pred = model_lgb.predict(X_test_scaled)
# Menyimpan skor akurasi ke dalam dictionary 'models'
models['LGBMClassifier_accuracy'] = accuracy_score(y_test, lgb_pred)

"""Kode ini digunakan untuk melakukan prediksi dan evaluasi model LightGBM yang telah dilatih sebelumnya. Model LightGBM digunakan untuk memprediksi label pada data uji yang sudah diskalakan (`X_test_scaled`) dengan memanggil metode `predict`, dan hasil prediksi disimpan dalam variabel `lgb_pred`. Selanjutnya, akurasi prediksi dihitung dengan membandingkan hasil prediksi `lgb_pred` dengan label sebenarnya `y_test` menggunakan fungsi `accuracy_score`. Nilai akurasi yang diperoleh kemudian disimpan dalam dictionary bernama `models` dengan kunci `'LGBMClassifier_accuracy'`, sehingga memudahkan penyimpanan dan perbandingan performa model LightGBM dengan model-model lain yang diuji.

## 11. Inisiasi Model Klasifikasi
"""

# Inisialisasi model-model klasifikasi
models = {
    "RandomForest": RandomForestClassifier(random_state=42),
    "ExtraTrees": ExtraTreesClassifier(random_state=42),
    "DecisionTree": DecisionTreeClassifier(random_state=42),
    "Bagging": BaggingClassifier(random_state=42),
    "LGBM": LGBMClassifier(random_state=42)
}

"""## 12. Evaluasi Model"""

# Dictionary untuk menyimpan nilai-nilai akurasi
accuracy_scores = {}

# Evaluasi setiap model
for name, model in models.items():
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)

    print(f"\n=== {name} ===")
    accuracy = accuracy_score(y_test, y_pred) # Get accuracy score
    accuracy_scores[name] = accuracy # Store accuracy score
    print("Accuracy:", accuracy)
    print("Classification Report:\n", classification_report(y_test, y_pred))

    # Buat confusion matrix
    cm = confusion_matrix(y_test, y_pred)

    # Plot heatmap
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
    plt.title(f"Confusion Matrix - {name}")
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.show()

"""Dari kode dan output diatas dapat disimpulkan bahwa:

1. Model RandomForest
- Memiliki Akurasi: 62.45%.
- Memiliki F1-score rata-rata tertimbang (weighted avg): 62%.
- Performa paling tinggi dari semua model (dalam hal akurasi)
- F1-score relatif merata di semua kelas.

2. Model ExtraTrees
- Memiliki Akurasi: 61.97%.
- Memiliki F1-score rata-rata tertimbang: 62%.
- Hampir setara dengan RandomForest  
- Kelas 3 (recall 0.67), 6(recall 0.73), dan 9(recall 0.66) memiliki recall yang cukup tinggi.

3. Model DecisionTree
- Memiliki Akurasi: 59.88%.
- Memiliki F1-score rata-rata tertimbang: 60%.
- Cukup seimbang dalam precision dan recall antar kelas.
- Performa cenderung lebih rendah dibanding model ensemble (RF, ET, Bagging).

4. Model Bagging
- Memiliki Akurasi: 61.56%.
- Memiliki F1-score rata-rata tertimbang: 61%.
- Hampir setara dengan RandomForest dan ExtraTrees.
- Bagging bisa mengurangi overfitting dari pohon tunggal.

5. Model LGBM (LightGBM)
- Memiliki Akurasi: 54.50%.
- Memiliki F1-score rata-rata tertimbang: 54%.
- Performa cukup baik di kelas 6 dan 5.


"""

# Buat sebuah pandas Series dari nilai-nilai akurasi yang sudah dikumpulkan
accuracy_series = pd.Series(accuracy_scores)

plt.figure(figsize=(10, 6))
# Menggunakan Series untuk membuat plot batang
accuracy_series.plot(kind='bar', color='#FF4500', edgecolor='gray', linewidth=1.2)
plt.title('Perbandingan Akurasi Model', fontsize=16, fontweight='bold')
plt.xlabel('Nama Model', fontsize=13)
plt.ylabel('Skor Akurasi', fontsize=13)
plt.grid(True, axis='y', linestyle=':', alpha=0.6)
plt.tight_layout()
plt.show()

"""Grafik batang pada gambar yang Anda tampilkan berjudul "Perbandingan Akurasi Model" menunjukkan visualisasi dari skor akurasi lima model klasifikasi yaitu RandomForest, ExtraTrees, DecisionTree, Bagging, dan LGBM. Selain itu Model ensemble berbasis pohon (RandomForest, ExtraTrees, Bagging) memberikan performa terbaik dalam hal akurasi. Model tunggal seperti DecisionTree lebih lemah. Model boosting seperti LGBM dalam kasus ini memiliki performa terendah."""